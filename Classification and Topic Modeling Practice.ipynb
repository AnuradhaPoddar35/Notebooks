{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Arxiv Data\n",
    "\n",
    "We're going to use a bunch of Arxiv physics papers for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're already in the directory with the papers, so we can use os.listdir() to get the file names\n",
    "filename_list = os.listdir()[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0301116', '0304232', '0303017', '0303225', '0302131']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that these file names are correct:\n",
    "filename_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read in all the files from the `filename_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in range(len(filename_list)):\n",
    "    \n",
    "    filename = filename_list[i]\n",
    "    \n",
    "    # errors='ignore' is added to deal with UnicodeDecodeErrors  \n",
    "    with open(filename, 'r', errors='ignore') as file:\n",
    "            file_contents = file.read()\n",
    "          \n",
    "    # Add document to corpus\n",
    "    corpus.append(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing LaTeX and other formatting artifacts that will cause issues with NMF and LDA\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import gensim.parsing.preprocessing as genpre\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def prep_text(text):\n",
    "     # this removes LaTeX formatting, citations, splits hyphens\n",
    "    myreg = r'\\\\[\\w]+[\\{| ]|\\$[^\\$]+\\$|\\(.+\\, *\\d{2,4}\\w*\\)|\\S*\\/\\/\\S*|[\\\\.,\\/#!$%\\^&\\*;:{}=_`\\'\\\"~()><\\|]|\\[.+\\]|\\d+|\\b\\w{1,2}\\b'\n",
    "    parsed_data = text.replace('-', ' ')\n",
    "    parsed_data = re.sub(myreg, '', parsed_data)\n",
    "    parsed_data = [lmtzr.lemmatize(w) for w in parsed_data.lower().split() if w not in genpre.STOPWORDS]\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [prep_text(document) for document in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`prep_text` didn't remove -everything-, but we will have many fewer artifacts than if we didn't run it at all. We can also scrape off some very common LaTeX phrases by passing them as stopwords when retraining the `TfIdfVectorizer`, and also by setting `max_df` to exclude words that occur in more than 90% of documents.\n",
    "\n",
    "See this [excellent blog post](https://medium.com/@omar.abdelbadie1/processing-text-for-topic-modeling-c355e907ab23) on why `prep_text` works to remove LaTeX artifacts. All credit goes to author Omar Abdelbadie for this method.\n",
    "\n",
    "Note that by using `prep_text` we've caused every entry in `corpus` to become a list containing a number of strings, rather than one big string for each entry. This is a problem for when we want to create our feature matrix, as `TfIdfVectorizer` is not compatible with a list of lists. We'll need to use `join` (a string method) to change each entry back to a string instead of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'latex file paper documentstylerevtex documentstylearticle tightenlines documentstylerevtex defbtt deftex beqequation eeqequation bdmdisplaymath edmdisplaymath beqaeqnarray eeqaeqnarray beqabeqnarray eeqabeqnarray partial dlrleftrightarrowpartial lraleftrightarrow symbolfootnotethefootnote footnote thefootnotefootnote alphfootnote footnote thefootnotesevenrmfootnote theequationsectionequation defnonumber deffootnote def@makefnmark pthss original slijedeci blok omogucava alfabetsko subnumeriranje visestrukim formulama upotreba pocinje prekida reseteqn saveeqn alpheqnsaveeqnequation saveeqnequation theequation sectionsaveeqn equation reseteqnequationsaveeqn theequationsectionequation document draft flushright nyu flushright nyu gravity induced smooth soliton marko kolanovi mail mk@nyuedu center cosmology particle physic department physic new york university new york today maketitle abstract consider gravity induced smooth finite thickness soliton graviton kinetic term coupled bulk scalar develops solitonic vacuum expectation value coupling kaluza klein mode soliton localized matter suppressed giving rise crossover distance d d behavior viewed finite thickness brane regularization model dvali gabadadze porrati abstract narrowtext newpage introduction equation brane world theory large infinite extra dimension recently provided insight number problem high energy physic possible relation model emerge fundamental higher dimensional theory described term string extra dimension realized nature valuable testing ground new idea particle physic gravity time believed extra dimension exist compact finite volume problem infinite volume extra dimension obtain dimensional force gravity object located brane work dgp shown dimensional newton force arises brane induced kinetic term model dvali gabadadze porrati dgp described action beqdgp xdy+ delta eeq coordinate extra dimension d curvature d metric d curvature constructed metric induced brane fundamental scale gravity scale characterizes brane rigidity order obtain correct value newton constant brane taken gev brane represented delta function thickness brane taken zero related model infinite extra dimension presented studied rele phenomenology action dgp studied dgkn shown scale bulk gravity low property model cosmological evolution new manifestation astronomical scale string theory realization examined furtdisstr note study similar induced enhanced gravity smooth soliton beqsys xdy+ chi eeq localized function representing smooth tension soliton linearized level feature dgp sys short dimensional gravity distance mediated metastable massless resonance width resonance distance gravity dimensional conclude sys finite thickness brane regularization dgp paper work simpler scalar gravity model capture main feature gravity variation strength kinetic term consequence dilaton like coupling bulk scalara exhibit solitonic vev neglect gravitational effect soliton equivalent fine tunning tension zero section study property spectrum lagrangian strength kinetic term function extra coordinate result applicable scalar gauge bulk field linearized gravity section investigate spectrum kaluza klein mode sys coupling soliton localized matter crossover distance suppression coupling mode matter localized soliton equivalent problem tunneling potential barrier new scale brane thickness contrary result kiri different regularization scheme considered conclude sys viewed finite thickness brane regularization action dgp appendix outline procedure finding spectrum fermionic mode kinetic term bulk fermion field varying extra dimension localization model non homogeneous kinetic term equation section investigate general property model strength kinetic term bulk field homogeneous infinite extra dimension let bulk field coupled kinetic term field beqsolmod chiphipartialphi+chipartialchi chi eeq function characterizes coupling field field potential obtain expectation value form soliton lagrangian field following form beqfirstl phipartialphi eeq field represent bulk scalar gauge field graviton linearized approximation dimensional spectrum firstl decompose field kaluza klein mode differential equation wave function beqekv ++ eeq taking equation ekv different eigenvalue cross multiplying eigenfunctions subtracting integrating length extra dimension orthogonality relation beqorth eeq normalization constant combining ekv orth beqnogo eeq non negative denominator numerator expression positive mean ghost tachions ghost tachions effective dimensional action obtained firstl introduce additional coupling field charge density localized soliton centered d effective theory coefficient coupling determined convolution matter profile wave function average wave function soliton localized matter beqconvo phiequiv psi eeq effective action mode read beqefac left partial right+phirho eeq fundamental scale zero mode normalizable choice integral finite single mode continuum function nonzero feature distinguishes case localization quasi localization order spectrum determine localization property mode specify function better understand connection shape localization property useful transform ekv related schroedinger problem beqschro equivphim + eeq localizing potential form beqlocpo left leftrightright eeq potential behave attractive repulsive barrier depends balance magnitude second derivative profile consider choice function lead localization spectrum excitation example gaussian profile scale determines brane width profile rise localized tower mode mass integer model localization gauge field repeat use starting point investigation soliton induced gravity section potential locpo result profile potential simple harmonic oscillator shifted constant zero point energy vanishes beqsho y eeq normalized wave function schro beqwfho eeq spectrum mass go like beqspho n eeq interaction mode charge located brane determined value wave function position charge example coupling charge beqcoupho rho eeq vanishes odd vanishing coupling odd value true smooth brane localize charge reason wave function mode odd odd matter localization profile coupling convo vanishes example exponentially decaying profile presented example localized profile finite integral localize mode naively expect schroedinger potential profile beqpot delta eeq spectrum mode consist single localized zero mode beqlzm eeq continuum scattering state starting potential charge located exchange field change dimensional law dimensional law distance smooth brane regularization dgp model equation section establish relation model dvali gabadadze porrati action sys linearized level let consider dimensional model scale fundamental scale determines action bulk filed potential bulk field governed higher brane scale scale determines width brane soliton field field coupled quadratically kinetic term coupling suppressed power fundamental scale beq left+chirightphipartialphi+ chipartialchi eeq let field get expectation value profile function firstl beqdgpr +leftrighte + eeq soliton scale bigger bulk scale coefficient huge number schroedinger potential locpo profile beqpotq + + eeq potential potq shown fig potential harmonic oscillator sho mm filefigepswidthcm footnotesizefigure potential potq solid line harmonic oscillator potential sho dashed line unit inverse potential unit mm small value potential coincides potential harmonic oscillator certain distance square cut potential rapidly drop zero behavior qualitatively predict spectrum state lowest bound state harmonic oscillator obtain width tunnel barrier interested case gravity want decay width zero mode mediate dimensional newton force brane higher mode mass irrelevant low energy physic decay width wkb approximation zero mode beqdecw expleft yyright eeq classical turning point width large value condition wkb validity satisfied classical turning point integral decw evaluated numerically large range value integral independent behaves power negligible numerical error wkb approximation zero mode decay width beqzmdw sim eeq wave function continuous kaluza klein spectrum solving schroedinger equation coupling mode convo matter localized soliton suppressed explore question universality coupling filed scalar gravity brane matter different type matter localized soliton different profile coupling convo gravity non universal argued problem non universality coupling fact desirable property model infinite extra dimension open possibility solving cosmological constant problem spoiling general covariance resulting dimensional theory pointed gia dvali theory gravity induced smooth brane rub adopt following framework violation universality suppressed soliton thickness scale potential scalar field form solitonic brane governed high mass scale mass standard model field lower cutoff particle come zero mode bulk field mass splitting higher order effect zero mode profile roughly soliton potential localizes zero mode bound state mass wave function state different lead different coupling convo large mass decoupled low energy physic let return spectrum potential potq schroedinger equation potq solved numerically simplicity matter profile evaluate coupling convo continuum mode qualitative behavior wave function follows outside wave function plane wave frequency inside wave function roughly gaussians mass dependent height constant width approximately coupling actual coupling evaluated mode numerically dependence coupling convo mass mode shown fig mm filefigepswidthcm footnotesizefigure suppression coupling coupling value outside graph range peak position resonant state harmonic oscillator log log plot graph multiplied shown inset solid line coefficient suppression coupling mm peak located mass zero zero mass graviton resonance responsible d force short distance resonance start coupling decay log log plot dependence half width peak magnitude evaluated numerical analysis sampling data large range value beq eeq metastable massless graviton resonance higher state harmonic oscillator mass particular unusual happening scale contrary result kiri different regularization advocated mass scale position log log graph fig newtonian potential exchange field mass short distance given beqnewt inftyphi approx eeq integral supported resonance width height large distance lightest mode contribute exchange coupling unsuppressed approximate beqnewtl inftyphi approx eeq behavior newtonian potential model dvali gabadadze porrati weak dimensional force mimicked exchange continuum massive graviton distance smaller crossover distance larger distance force dimensional crossover distance coincides crossover distance dgp order reproduce correct newton constant scale order planck scale beq rc eeq linearized level exchange massive spin state give wrong tensor structure propagator vdvz shown dis non linear effect cure problem model dgp conjecture similar mechanism occurs model hand investigation effect spectrum induced gravity codimensions currently progress pap cm acknowledgment cm like thank alex vilenkin useful comment grateful gia dvali discussion comment encouraging manuscript public newpage appendix method fermion equation outline procedure finding spectrum bulk fermion field kinetic term homogeneous extra dimension action consider beqfer psipartialpsi eeq dirac algebra d satisfied choice d gamma matrix equation motion independent solved ansatz beqaazap psileft gm+hmright eeqa spinors form d dirac spinor wave function beqasoltocop gmamsin+bmcoshmamcos bmsin eeqa wave function case dimensional effective action different integrates profile plugging soltocop fer integrating obtain following d action beqfdaf leftpsirlappartial+ psi+ right eeq infinite dimensional matrix given fourier transform profile beq dyfcos eeq clearly finding spectrum fermion coupling reduced problem diagonalization infinite hermitian matrix diagonalization step write schematically beqadiagon psidaggerrlappsi+psidaggerpsilongrightarrow psidaggerrlappartial+psidaggerumudaggerpsi psidaggerrlappsi+ psidagger umudaggerdaggerequiv psirlap+psi eeqa rotated fermion sequentially orthogonal matrix chosen diagonalize kinetic mass term simplest example case recover ordinary tower massive fermion simple example case entry eigenvalue matrix zero infinite number positive mode mode mode nonzero kinetic term matrix diagonalizes case entry diagonal go lower left upper right corner entry column entry row entry zero matrix zero diagonal single propagating mode mass zero interesting spectrum induced d fermion diagonalization infinite matrix compare result obtained inducing d kinetic term brane dksdick appendix newpage reference dgp dvali gabadadze porrati d gravity brane d minkowski space phys lett b rele gregory rubakov sibiryakov opening extra dimension ultra large scale phys rev lett csaki erlich hollowood quasi localization gravity resonant mode phys rev lett dgkn dvali gabadadze kolanovic nitti power brane induced gravity phys rev citation hep dvali gabadadze kolanovic nitti scale gravity phys rev citation hep carena delgado lykken pokorski quiros wagner brane effect extra dimensional scenario tale graviton nucl phys furt deffayetuy deffayet cosmology brane minkowski bulk phys lett citation hep dicknp co dick standard cosmology dgp brane model acta phys polon citation hep deffayetpu co deffayet dvali gabadadze accelerated universe gravity leaking extra dimension phys rev citation astro kofinases co kofinas general brane cosmology term minkowski bulk jhep citation hep ponton poppitz casimir energy radius stabilization dimensional orbifolds jhep kolanovic dgp brane gravity conductor phys rev kofinas papantonopoulos zamarias black hole solution braneworlds induced gravity phys rev middleton siopsis fat branes infinite volume extra space arxivhep discontinuity discontinuity dis deffayet dvali gabadadze vainshtein nonperturbative continuity graviton mass versus perturbative discontinuity phys rev citation hep lue cosmic string brane world theory metastable graviton arxivhep citation hep gruzinov graviton mass arxivastro citation astro porraticp porrati fully covariant van dam veltman zakharov discontinuity absence thereof arxivhep citation hep dvali gruzinov zaldarriaga accelerated universe moon arxivhep citation hep lue starkman gravitational leakage extra dimension probing dark energy local gravity arxivastro citation astro str corley lowe ramgoolam einstein hilbert action brane bulk graviton jhep antoniadis minasian vanhove non compact calabi yau manifold localized gravity nucl phys kiri kiritsis tetradis tomaras branes d gravity jhep dvali vilenkin solitonic branes brane annihilation arxivhep rub dubovsky rubakov brane induced gravity extra dimension violation equivalence principle ghost arxivhep add arkani hamed dimopoulos dvali phys lett b antoniadis arkani hamed dimopoulos dvali phys lett b add arkani hamed dimopoulos dvali phys rev d vdvz vdvz van dam veltman massive massless yang mill gravitational field nucl phys vainshtein problem nonvanishing gravitation mass phys lett pap dvali gabadadze kolanovic preparation dks dvali kolanovic smirnov preparation dick dick mcarthur photon mass brane phys lett reference document'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = ' '.join(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Feature Matrix\n",
    "\n",
    "We have exactly 500 documents to work with. Now we can turn our corpus into a matrix of Term Frequency Inverse Document Frequency (TF-IDF) features using `sklearn`'s `TfidfVectorizer()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<500x20000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 203574 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again ignoring any UnicodeDecodeErrors\n",
    "vectorizer = TfidfVectorizer(decode_error = 'ignore', max_df = 0.9, ngram_range = (2, 2), max_features = 20000)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the vocabulary that was learned by the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latex file': 9739,\n",
       " 'beqequation eeqequation': 1153,\n",
       " 'beqaeqnarray eeqaeqnarray': 1151,\n",
       " 'footnote thefootnotefootnote': 7264,\n",
       " 'document draft': 4900,\n",
       " 'particle physic': 12985,\n",
       " 'physic department': 13244,\n",
       " 'department physic': 4203,\n",
       " 'new york': 11769,\n",
       " 'university new': 19105,\n",
       " 'today maketitle': 18731,\n",
       " 'maketitle abstract': 10570,\n",
       " 'abstract consider': 46,\n",
       " 'finite thickness': 7077,\n",
       " 'kinetic term': 9515,\n",
       " 'bulk scalar': 1872,\n",
       " 'vacuum expectation': 19212,\n",
       " 'expectation value': 6420,\n",
       " 'value coupling': 19273,\n",
       " 'kaluza klein': 9435}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast the vocab dict to a list so we can print just a subset of the dict\n",
    "\n",
    "first20_vocab = {k: vectorizer.vocabulary_[k] for k in list(vectorizer.vocabulary_)[:20]}\n",
    "first20_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 word exactly\n",
      "1 non lymext\n",
      "2 entropy like\n",
      "3 baye phys\n",
      "4 main difficulty\n",
      "5 covariant quantized\n",
      "6 covariant admits\n",
      "7 give displayed\n",
      "8 line oneloop\n",
      "9 dltkphi unlike\n",
      "10 remember non\n",
      "11 specifying exact\n",
      "12 order green\n",
      "13 hole predicts\n",
      "14 lqcmartin bojowaldisotropic\n",
      "15 start description\n",
      "16 let separate\n",
      "17 bigvevbigllanglebigrrangle bigcomm\n",
      "18 seiberg gauged\n",
      "19 chosen phase\n"
     ]
    }
   ],
   "source": [
    "# Similar to above, use itertools to avoid printing the entire (massive) set to screen\n",
    "import itertools\n",
    "\n",
    "for i, val in enumerate(itertools.islice(vectorizer.stop_words_, 20)):\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of LaTeX and nonsense terms, as well as some physics terms, were caught in the filter created by `max_df`. The benefit should outweigh the cost of excluding these particular physics terms. (After all, they must not be very distinctive phrases if they're occurring in 90% of papers.)\n",
    "\n",
    "The top of the vocabulary showed some additional phrases that occur frequently and are not informative to us. We'll go ahead and remove those low-hanging fruit using by retraining the vectorizer and passing these stop-phrases as a list.\n",
    "\n",
    "(Normally it would not make sense to slice a dictionary this way, but after having run the vectorizer repeatedly and seeing the order the terms are stored in memory, we can make the call to exclude the 15 phrases that tend to float to the top.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stopwords = list(vectorizer.vocabulary_)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<500x20000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 203574 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(decode_error='ignore', max_df=0.9, ngram_range=(2, 2), \n",
    "                             max_features = 20000, stop_words=additional_stopwords)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll do some topic modeling.\n",
    "\n",
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NMF\n",
    "nmf_model = NMF(n_components = 10, solver = 'mu')\n",
    "\n",
    "# Create variable to make it easy to retrieve topics\n",
    "idx_to_word = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=10, random_state=None, shuffle=False, solver='mu',\n",
       "  tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_components = nmf_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: def def, rev citation, jhep citation, arxivhep citation, gauge theory, nucl phys, lett citation, phys citation, hep citation, citation hep\n",
      "Topic 2: defrelax defem, lie group, lie algebra, moody algebra, kac moody, defrelax defrelax, defssbchar defssbchar, em em, defem defem, def def\n",
      "Topic 3: einstein equation, momentum tensor, energy momentum, scale factor, cosmic string, extra dimension, energy density, cosmological constant, phys rev, scalar field\n",
      "Topic 4: sitter space, reissner nordstr, quasinormal mode, near horizon, quasinormal frequency, hole entropy, quantum gravity, phys rev, schwarzschild black, black hole\n",
      "Topic 5: universal solution, non bps, rolling tachyon, string theory, tachyon condensation, field theory, boundary state, open string, string field, closed string\n",
      "Topic 6: bmn operator, zero mode, maximally supersymmetric, gamma gamma, type iib, cone gauge, penrose limit, light cone, wave background, plane wave\n",
      "Topic 7: riemann surface, witten curve, effective superpotential, dijkgraaf vafa, seiberg witten, supersymmetric gauge, modulus space, fuzzy sphere, gauge theory, matrix model\n",
      "Topic 8: eq left, right nonumber, bf equation, nonumber left, right equation, equation left, right right, left left, right left, left right\n",
      "Topic 9: yang mill, phys lett, lie algebra, field theory, phase space, gauge theory, space time, nucl phys, star product, hilbert space\n",
      "Topic 10: partial equation, given equation, affine algebra, equation partial, array array, right equation, equation left, left array, array right, equation equation\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(nmf_components):\n",
    "    print(\"Topic {}: {}\".format(i + 1, \", \".join([str(x) for x in idx_to_word[topic.argsort()[-10:]]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exciting! We have a few topics here that are composed of LaTeX specifications (like 1, 2, 8, and 10), but the others are clearly relevant to particular areas of physics.\n",
    "\n",
    "Let's try out some LDA as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model = LatentDirichletAllocation(max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda_model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: charge mass, phys rev, right left, fudge factor, wilson line, observed value, left right, mass proton, carr rees, om om\n",
      "Topic 2: non borel, illustrated figure, scale factor, plane wave, previous paragraph, gauge theory, citation hep, matrix model, def def, path path\n",
      "Topic 3: hc eta, big lv, strominger vafa, gubser klebanov, nucl phys, extra dimension, equation equation, langevin equation, world volume, citation hep\n",
      "Topic 4: langevin equation, equation lyter, eqnarray lyter, pt defhskipptvtop, theequationsectionequationlyter eqnarray, defhskipptvtop baselineskipptpt, change direction, langevin eq, baselineskipptpt pt, wh wh\n",
      "Topic 5: hep citation, gauge theory, nucl phys, left right, equation equation, field theory, phys rev, black hole, citation hep, def def\n",
      "Topic 6: quasinormal frequency, partition type, fermionic matrix, large limit, crossing partition, noncommutative probability, matrix vector, non crossing, nm nv, black hole\n",
      "Topic 7: conserved quantity, columncolor columncolor, sd brane, picture includegraphicsacosfeps, citation hep, scale factor, dnls model, sm brane, def def, internal space\n",
      "Topic 8: function non, function invariant, product hilbert, product complex, displaymath displaymath, nuclear physic, phin phin, psin psin, inner product, psin phin\n",
      "Topic 9: scalar field, putvector putvector, rho big, magnetic flux, nucl phys, nambu goto, goto action, big rho, weyl invariant, parent action\n",
      "Topic 10: tachyon background, chi chi, string theory, phys rev, nojiri odintsov, gauge transformation, domain wall, citation hep, ym eqnarray, cosmic string\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(lda_model.components_):\n",
    "    print(\"Topic {}: {}\".format(i + 1, \", \".join([str(x) for x in idx_to_word[topic.argsort()[-10:]]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, the topics generated by LDA are not very interesting or distinct. It looks like NMF is a more appropriate topic modeling method for this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
